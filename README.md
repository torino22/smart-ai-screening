# ğŸ§  Smart Interview Screening System

An AI-powered interview assistant that transcribes candidate audio, extracts key information using NLP, matches relevant FAQs via semantic search (RAG), and returns audio/text-based responsesâ€”all with an interactive Streamlit frontend.

---

## ğŸ“¸ Quick Start Guide

### Step 1: Upload Interview Audio (for candidates)

  1. Enter a **Session ID** for the candidate
    NOTE: For use ease of use you can enter the name or email as session_id (e.g., `john_doe_interview`)
  2. Choose how to add audio:
    - **Upload File**: Select audio file (wav, mp3, mp4, m4a)
    - **Record Audio**: Click record button to capture live audio
  3. Click **Upload Audio** to process

### Step 2: Access Evaluation (for screening authority)

  1. Click **Evaluate Candidates** 
  2. Enter password when prompted (which will be stored in .env for streamlit use)
  3. You're now in the evaluation interface

### Step 3: Evaluate Candidate

  1. Enter the **Session ID** of candidate you want to evaluate
  2. **Generate FAQ** to get suggested questions
  3. **Chat Interface**:
    - Type your question in the text box
    - Click **Send** 
    - AI responds with audio
    - View chat history above


---


## ğŸš€ Features

  - ğŸ“ Upload or record candidate audio
  - ğŸ” Password-protected access (admin only access for evaluation)
  - â“ AI-generated FAQ questions
  - ğŸ’¬ Text-to-audio chat evaluation
  - ğŸ”„ Multiple candidate sessions (multitenant)


---


## Tips

- Use clear, unique session IDs
- Green status = system ready
- Click FAQ questions to auto-fill
- Use **Logout** to switch candidates safely
-


---


## ğŸ“ Project Structure

<pre><code>
  smart_ai_screening/
  â”œâ”€â”€ venv/                            # Virtual environment (library root)
  â”œâ”€â”€ app/                             # Main application directory
  â”‚   â”œâ”€â”€ config/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ settings.py
  â”‚   â”œâ”€â”€ db/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ models.py
  â”‚   â”‚   â””â”€â”€ setup.py
  â”‚   â”œâ”€â”€ pydantics/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ schemas.py
  â”‚   â”œâ”€â”€ routers/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ chat.py
  â”‚   â”‚   â””â”€â”€ file_io.py
  â”‚   â”œâ”€â”€ services/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ file_io.py
  â”‚   â”‚   â”œâ”€â”€ llm_service.py
  â”‚   â”‚   â”œâ”€â”€ nsr.py
  â”‚   â”‚   â”œâ”€â”€ sql.py
  â”‚   â”‚   â”œâ”€â”€ streamlit_ui.py
  â”‚   â”‚   â””â”€â”€ vector.py
  â”‚   â”œâ”€â”€ templates/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ chat_prompt_template.py
  â”‚   â”‚   â”œâ”€â”€ generic_faq.py
  â”‚   â”‚   â””â”€â”€ skills.txt
  â”‚   â”œâ”€â”€ utils/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ logger.py
  â”‚   â””â”€â”€ __init__.py
  â”œâ”€â”€ chroma_db/                     # Vector database directory
  â”œâ”€â”€ logs/                          # Application logs
  â”œâ”€â”€ output_audio/                  # Audio output files
  â”œâ”€â”€ uploads/                       # File uploads directory
  â”œâ”€â”€ .env                           # Environment variables
  â”œâ”€â”€ .gitignore                     # Git ignore file
  â”œâ”€â”€ database.db                    # SQLite database
  â”œâ”€â”€ database.db-shm                # SQLite shared memory file
  â”œâ”€â”€ database.db-wal                # SQLite write-ahead log
  â”œâ”€â”€ main.py                        # Main application entry point
  â””â”€â”€ requirements.txt               # Python dependencies
</code></pre>


---


## ğŸ“ Project Structure Overview

### Core Application (app/)

- **config/:** Application configuration and settings
- **db/:** Database models and setup scripts
- **pydantics/:** Data validation schemas using Pydantic
- **routers/:** API route handlers (chat, file I/O)
- **services/:** Business logic services (LLM, vector search, SQL, etc.)
- **templates/:** Prompt templates and skill definitions
- **utils/:** Utility functions (logging, etc.)

### Data & Storage

- **chroma_db/:** Vector database for embeddings and similarity search
- **uploads/:** User-uploaded files
- **output_audio/:** Generated audio files
- **database.db:** Main SQLite database with associated files

### Configuration & Dependencies

- **.env:** Environment variables and secrets
- **requirements.txt:** Python package dependencies
- **venv/:** Virtual environment for isolated dependencies

### Logs & Metadata

- **logs/:** Application log files
- **.gitignore:** Git version control ignore rules



---


## ğŸ’¬ Interview Chat Interface

- Input session ID (linked to uploaded audio)
- Ask questions about the candidate (e.g., _"Does he know Python?"_)
- AI evaluates candidate responses based on transcribed self-introduction
- FAQ responses are generated and spoken using text-to-speech
- Button: `Generate FAQ` to display hardcoded Q&A
- Button: `Evaluate Candidates` triggers backend processing


---


## âš™ï¸ Tech Stack

<pre><code>

| Layer        | Tools & Libraries                           |
|--------------|---------------------------------------------|
| Backend      | FastAPI, SQLAlchemy                         |
| ML/NLP       | HuggingFace Transformers, Whisper, ChromaDB |
| Audio        | ffmpeg-python, edge-tts                     |
| Frontend     | Streamlit                                   |
| Database     | SQLite                                      |

</code></pre>


---


## ğŸ§ª Sample Workflow

1. **User uploads `John_self_intro_audio.wav`**

2. **Backend transcribes to text:**
```bash
   > "Hi, Iâ€™m John. I have 4 years of experience in Python and Django..."
```

3. **Named Entity Recognition extracts:**

```bash
   {
     "name": "John",
     "skills": ["Python", "Django"],
     "Location": "Chennai",
     "Company_Name": "InnoTech Solutions"
   }
```

4. **User asks:**

```bash
"Does he know Python?"
```

5. **System confirms via extracted skills and responds via TTS.**


---


## ğŸ› ï¸ Installation

### ğŸ”§ Backend (FastAPI)
```bash
git clone https://github.com/yourusername/smart-interview-assistant
cd <to the dir where stremlit_ui.py exist>
pip install -r requirements.txt
uvicorn main:app --reload
```


---


## ğŸ–¥ï¸ Frontend (Streamlit)

```bash
cd <to your root folder where main.py exsist>
streamlit run app.py
```


---


## .env setup

```bash
OPENAI_API_KEY=<openAI-key>
BACKEND_ROOT_URL=<{root_url}>
STREAMLIT_ADMIN_PASSWORD=<admin-pswd>
```


---


## ğŸ§¾ Deliverables

-  âœ… Codebase (backend + frontend)
-  ğŸ§ Sample audio files
-  â“ Predefined FAQs and embeddings
-  ğŸ“– Complete README
-  ğŸ—ƒï¸ Entity extraction schema with JSON output


---
